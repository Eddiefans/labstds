{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70086771-ad90-497d-9b51-22626c9cce63",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
   "metadata": {},
   "source": [
    "|                |   |\n",
    ":----------------|---|\n",
    "| **Nombre**     | Eddie Aguilar |\n",
    "| **Fecha**      | 17/02/2025  |\n",
    "| **Expediente** | 739352  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
   "metadata": {},
   "source": [
    "Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
    "\n",
    "¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
   "metadata": {},
   "source": [
    "Ya que es conveniente dividir un modelo en subset de entrenamiento y un subset de validación, esto para poder saber si el modelo planteado se ajusta bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
   "metadata": {},
   "source": [
    "Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
   "metadata": {},
   "source": [
    "Ya que en ese caso no tendríamos datos con los cuales validar si nuestro modelo se ajusta bien o no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
   "metadata": {},
   "source": [
    "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
    "\n",
    "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
    "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
    "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
    "\n",
    "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
    "\n",
    "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
    "\n",
    "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
   "metadata": {},
   "source": [
    "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
    "1. Saca una muestra del dataset.\n",
    "2. Entrena tu modelo con las $n-1$ muestras.\n",
    "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "4. Regresa la muestra al dataset.\n",
    "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
    "6. Calcula la media y desviación estándar de los métricos guardados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
   "metadata": {},
   "source": [
    "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
   "metadata": {},
   "source": [
    "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89510da9-15a9-41e5-bd0e-855291acec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_excel(r\"C:\\Users\\AgJo413\\Documents\\GitHub\\Lab_std\\labstds\\Data\\Motor Trend Car Road Tests.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7199ca1-32f0-463b-925f-76613d608a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40ad85dc-3106-4430-9ed2-b6354e00d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8343d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(trainx, trainy, testx, testy):\n",
    "    model = LinearRegression()\n",
    "    model.fit(trainx, trainy)\n",
    "    ypred = model.predict(testx)\n",
    "    return ypred\n",
    "\n",
    "def MSE(ypred, testy):\n",
    "    return mean_squared_error(testy, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70e42adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE has an average of: 12.181558006901943\n",
      "MSE has a standard deviation of: 17.067399871888504\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "for i in range(len(data)):\n",
    "    train = data.iloc[data.index != i]\n",
    "    test = data.iloc[[i], :]\n",
    "    trainx = train.loc[:, train.columns != \"mpg\"]\n",
    "    trainy = train.loc[:, train.columns == \"mpg\"]\n",
    "    testx = test.loc[:, test.columns != \"mpg\"]\n",
    "    testy = test.loc[:, test.columns == \"mpg\"]\n",
    "    ypred = modeling(trainx, trainy, testx, testy)\n",
    "    mses.append(MSE(ypred, testy))\n",
    "\n",
    "print(\"MSE has an average of: {}\".format(np.mean(mses)))\n",
    "print(\"MSE has a standard deviation of: {}\".format(np.std(mses)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea",
   "metadata": {},
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"mpg\"])\n",
    "y = data[\"mpg\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "ypred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc969c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.609200938020331"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(ypred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ee166-b442-49f8-bf40-db9aaf9c3db8",
   "metadata": {},
   "source": [
    "El promedio de MSE dentro de esta cross-validation nos ayuda para poder comprar nuestro modelo con esta media, de esta forma, en teoría nuestro modelo con todos los datos debería tener mejor calificación/valor que este promedio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad2cdd",
   "metadata": {},
   "source": [
    "Si la desviación estándar es pqueña significa que los folders no cambia mucho de uno a otro. Si es alta significa que hay folds en los que estás dejando información importante o que tiene mucha importancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
   "metadata": {},
   "source": [
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
   "metadata": {},
   "source": [
    "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
   "metadata": {},
   "source": [
    "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 8) (20640,)\n",
      "Dataset Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Dataset Target: ['MedHouseVal']\n",
      "(20640, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "print(\"Dataset Target:\", housing.target_names)\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8570a4-76bb-4d81-a90b-43647b0df438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(X, columns=housing.feature_names)\n",
    "data[housing.target_names[0]] = y\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd21581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>2.9542</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.074581</td>\n",
       "      <td>1.143075</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>3.526636</td>\n",
       "      <td>33.85</td>\n",
       "      <td>-117.30</td>\n",
       "      <td>1.27900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8854</th>\n",
       "      <td>15.0001</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.710145</td>\n",
       "      <td>1.028986</td>\n",
       "      <td>408.0</td>\n",
       "      <td>2.956522</td>\n",
       "      <td>34.07</td>\n",
       "      <td>-118.41</td>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16294</th>\n",
       "      <td>1.5539</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>1.087356</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>2.935632</td>\n",
       "      <td>37.96</td>\n",
       "      <td>-121.23</td>\n",
       "      <td>0.59200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>2.2269</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.020436</td>\n",
       "      <td>1.055858</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>2.335150</td>\n",
       "      <td>38.74</td>\n",
       "      <td>-120.83</td>\n",
       "      <td>1.28300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9712</th>\n",
       "      <td>3.6875</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.979277</td>\n",
       "      <td>1.052072</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>2.263018</td>\n",
       "      <td>36.66</td>\n",
       "      <td>-121.67</td>\n",
       "      <td>1.89700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "12090   2.9542      15.0  6.074581   1.143075      2317.0  3.526636     33.85   \n",
       "8854   15.0001      52.0  8.710145   1.028986       408.0  2.956522     34.07   \n",
       "16294   1.5539      44.0  5.066667   1.087356      1277.0  2.935632     37.96   \n",
       "1950    2.2269      17.0  5.020436   1.055858      1714.0  2.335150     38.74   \n",
       "9712    3.6875      19.0  4.979277   1.052072      4259.0  2.263018     36.66   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "12090    -117.30      1.27900  \n",
       "8854     -118.41      5.00001  \n",
       "16294    -121.23      0.59200  \n",
       "1950     -120.83      1.28300  \n",
       "9712     -121.67      1.89700  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled = data.sample(frac=1)\n",
    "data_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f44358-f47d-493b-93cf-10aa2314fa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE has an average of: 0.528237096685978\n",
      "MSE has a standard deviation of: 0.43472862510176086\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "for i in range(0, len(data_shuffled), 10):\n",
    "    test = data_shuffled.iloc[i:i+10, :]\n",
    "    train = data_shuffled.drop(test.index)\n",
    "    trainx = train.loc[:, train.columns != \"MedHouseVal\"]\n",
    "    trainy = train.loc[:, train.columns == \"MedHouseVal\"]\n",
    "    testx = test.loc[:, test.columns != \"MedHouseVal\"]\n",
    "    testy = test.loc[:, test.columns == \"MedHouseVal\"]\n",
    "    ypred = modeling(trainx, trainy, testx, testy)\n",
    "    mses.append(MSE(ypred, testy))\n",
    "\n",
    "print(\"MSE has an average of: {}\".format(np.mean(mses)))\n",
    "print(\"MSE has a standard deviation of: {}\".format(np.std(mses)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6019478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"MedHouseVal\"])\n",
    "y = data[\"MedHouseVal\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "ypred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd4e329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5243209861846072"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(ypred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7098f-a1de-4508-b3ff-af1484561856",
   "metadata": {},
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
   "metadata": {},
   "source": [
    "El promedio de MSE dentro de esta cross-validation nos ayuda para poder comprar nuestro modelo con esta media, de esta forma, en teoría nuestro modelo con todos los datos debería tener mejor calificación/valor que este promedio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c8039-5b38-4835-a523-d4f6f7a7040b",
   "metadata": {},
   "source": [
    "Si la desviación estándar es pqueña significa que los folders no cambia mucho de uno a otro. Si es alta significa que hay folds en los que estás dejando información importante o que tiene mucha importancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72acbe",
   "metadata": {},
   "source": [
    "En este caso, nuestro modelo está muy por debajo del promedio, entonces puede ser buena idea replantear ese modelo. Aunque también la significacnia o relevancia de esta delta es directmanete proporcional a la desviación estándar, una pequeña desviación estandar podría justificar un delta muy pequeño. Un siguiente paso podría ser hacer una prueba de hipotesis donde planteemos si esta diferencia realmente es dependiente al cambio de columnas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
   "metadata": {},
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
